\chapter{Peer-Assisted Content Delivery}

\section{Introduction}

Streaming content, especially video, represents a significant fraction of the traffic volume on the Internet, and it has become a standard practice to deliver this type of content using Content Delivery Networks (CDNs) such as Akamai and Limelight for better scaling and quality of experience for the end users. 
For example, YouTube uses Google cache and MTV uses Akamai in their operations.

With the spread of broadband Internet access at a reasonable flat monthly rate, users are connected to the Internet 24 hours a day and they can download and share multimedia content. P2P (peer to peer) applications are also widely deployed. 
In China, P2P is very popular; we see many P2P applications from China such as PPLive, PPStream, UUSe, Xunlei, etc. \cite{Vu:2010:UOC:1865106.1865115}. 
Some news broadcasters also rely on P2P technology to deliver popular live events. 
For example, CNN uses the Octoshape \cite{octoshape} solution that enables their broadcast to scale and offer good video quality as the number of users increases.

From the Internet provider point of view, the presence of so many always-on users suggests that it is possible to delegate a portion of computing, storage and networking tasks to the users, thus creating P2P networks where users can share files and multimedia content. 
Starting from file sharing protocols, P2P architectures have evolved toward video on demand and support for live events.

%A P2P based architecture usually requires a sufficient number of nodes supplying the data (seeders) to start the distribution process among the joining peers.  
%A peer usually offers a low outbound streaming rate due to the traditional asymmetrical DSL home connectivity and hence multiple peers must jointly stream contents to a requesting peer (leecher).  
%The decentralized, uncoordinated operation implies that scaling to a high number of peers comes with side effects.  
%Typical problems of a P2P streaming architecture are low stream quality with undesirable disruptions, resource unfairness due to heterogeneous peer resources, and high startup delay.  
%Moreover, current P2P applications are not aware of the underlying network and may conflict with the ISP routing policies and business model.

%A number of P2P streaming applications have been designed, analyzed and deployed, attracting a significant number of users.  
%Research studies and deployment experiences have both demonstrated that P2P is a promising solution in terms of scalability and deployment costs.  
%On the other hand, the heterogeneous nature and unstable behavior of the peers contributing bandwidth and computational resources, along with the networking issues, affect the user experience and limit the commercial success of P2P video streaming applications.
Alternatively, video contents can be efficiently distributed on services offered by managed network architectures and CDN companies.
The major issues of CDN are high deployment cost and good but not unlimited scalability in the long term.  
Given the complementary features of P2P and CDN, in recent years some hybrid solutions have been proposed and applied to the operational of CDN \cite{Huang:2008:UHC:1496046.1496064,4772628,Yin:2009:DDH:1631272.1631279} to take the best of both approaches.
In Peer assisted CDN, users can download content from CDN nodes from or other users or peers. 
A user may cache the content after download to serve requests from other users. 
Due to the complexity of the behavior of peers, the process should be done in the home gateway user where the ISP can control it.

In this work, we will revisit Guo et al.,'s  \cite{1613869} PROP as a basis to evaluate a peer-assisted CDN and propose an improvement to the model for the PROP.
We will take Youtube as an example of an Internet VoD service model.
In the Youtube service model, we can get data such as (1) the time when a video is uploaded and (2) number of access or number of view.
We can get such data through Youtube'API service.
%The information of (1) the time when a video is uploaded and (2) number of access or number of view will be used for helping PROP.
In seminal work, Borghol et al., \cite{Borghol:2011:CMP:2039452.2039717} used above information to estimate when a video will become very popular.
They divide a video's popularity into three phases: before-peak phase, at-peak phase, and after-peak phase.
We will use an estimate of a video's popularity phases for helping PROP.
We will explain video popularity in Sect.\ref{popularity}.
%We also examine the characteristics of Internet VoD by investigating real-world datasets obtained from Youtube.
%We estimate the video popularity phase.
%Information of video popularity phase will be used for caching strategy
%In P2P assisted CDN for video on demand (VoD), most of researcher assume that catalog of video popularity rank is already established following zipf distribution.  
%This become basis for P2P assisted CDN model in PROP \cite{1613869}.
%Our work is quite different whereas we will use VoD view popularity to aid the PROP model.
%We use Youtube VoD view model for this purpose.
%In Youtube, video view popularity has three phase which is before-peak, at-peak, and after-peak \cite{Borghol:2011:CMP:2039452.2039717} which we will explain later in sect.\ref{popularity}.
Our contribution is follows:
(1) We use the idea of VoD view popularity model to aid the PROP model. 
To the best of our knowledge, the combination of the PROP model and the VoD view popularity model is new.
(2) From simulation-based experiments, we find that peer contributions in our model are almost as good as those in PROP while the numbers of replicas are lower than PROP resulting in a reduction of resources required.


%%related work pindah ke chapter 2

\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/timetopeak.eps}
\end{center}
\caption{Time to peak empirical distribution data from \cite{Borghol:2011:CMP:2039452.2039717}.}
\label{fig:timetopeak}
\end{figure} 




\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/datadistribution.eps}
\end{center}
\caption{View rate distribution versus week relative to at-peak phase week for every video in Youtube datasets, where y-axis in log scale.
We shift the week relative to to at-peak phase week.
Every point lies in negative x-axis mean view rate of every video in before-peak phase.
Every point lies in x-axis$=0$ mean view rate of every video at-peak phase. 
Every point lies in positive x-axis mean view rate of every video in after-peak phase.
Data from \cite{Borghol:2011:CMP:2039452.2039717}.
}
\label{fig:viewratedistribution}
\end{figure} 


\section{Determining Internet VoD Popularity Phase}\label{popularity}

The objective of determining the Internet VoD popularity phase is to determine whether a video is at before-peak, at-peak, or after-peak phase, to be used by peers in their caching strategy.
For this purpose we use the Youtube content popularity dataset from Borghol et. al.,\cite{Borghol:2011:CMP:2039452.2039717}  which contains the data of 29791 videos, including the view count and upload time, during 36 weeks of measurements.
Figure~\ref{fig:timetopeak} is cummulative distribution function (CDF) the time-to-peak distribution from Borghol et. al.,\cite{Borghol:2011:CMP:2039452.2039717}  which shows that around three-quarters of the videos peak within the first six weeks after upload.
The time-to-peak is exponentially distributed up-to the sixth week, and it is uniform beyond the sixth week.
Borghol et al., \cite{Borghol:2011:CMP:2039452.2039717} define time-to-peak for a video as its age (time since upload) at which its weekly viewing rate is the highest during measurement (from the first week until end of measurement).
Because we know the peak time (at-peak phase) of every video, we can also find the before-peak phase and after-phase of every video. 
For detail we refer the readers to \cite{Borghol:2011:CMP:2039452.2039717}.

Suppose a video $v$ in Borghol dataset has a viewing rate $r_v(t)$, $0 <= t < t_f$, and $r_v(t)$ peaks at $t_{vp}$.
The data is transformed by including the relative time-to-peak, such that each data point is a 2-tuple: video rate and relative time to peak, i.e., $rp_v(t) = ( r_v(t), tp(t) ), tp(t) = t - t_{vp}$.
Figure~\ref{fig:viewratedistribution} shows the Borghol's dataset with time axis for each video is translated by $t_{vp}$ to the left, such that each video peaks at time $0$.


% \begin{figure}[!t]
% \begin{center}
% \includegraphics[scale=0.7]{../../hindawi/graphs/transformasi.eps}
% \end{center}
% \caption{Transformation of view rate distribution. We add week number and make it as $x$-axis, View rate as $y$-axis, and relative week to peak as $z$-axis.}
% \label{fig:viewratedistexample}
% \end{figure} 

% \begin{figure}[!t]
% \begin{center}
% \includegraphics[scale=0.7]{../../hindawi/graphs/transformasi3.eps}
% \end{center}
% \caption{2D visualization of view rate distribution after transformation where $x$-axis is week number, $y$-axis is view rate.}
% \label{fig:viewratedistexamplered}
% \end{figure} 

\begin{algorithm}
\caption{Averaging relative weeks from the nearest neighbor points}
\label{alg2}
\begin{algorithmic}[1]
\REQUIRE {dataset that consist of weeknumber, viewrate, and relative week to at peak.}

\STATE $t$ $\leftarrow$ read(weeknumber) \COMMENT{read week number from dataset}
\STATE $r_v$ $\leftarrow$ read(viewrate) \COMMENT{read view rate from dataset}
\STATE $tp$ $\leftarrow$ read(relativeweeksatpeak) \COMMENT{read relative week at peak from dataset}

%\COMMENT{a requested video has week number and view rate}
\STATE $t_e$ \COMMENT{week number of a requested video}
\STATE $r_e$ \COMMENT{view rate of a requested video}

\STATE $t_e^{before}$ $\leftarrow$ $(t_e - 1)$ \COMMENT{at one week before}
\STATE $tp_{before}$ $\leftarrow$ $find\_tp(t_e^{before},r_e,t,r_v,tp)$

\STATE $t_e^{at}$ $\leftarrow$ $(t_e)$ \COMMENT{at same week}
\STATE $tp_{at}$ $\leftarrow$ $find\_tp(t_e^{at},r_e,t,r_v,tp)$

\STATE $t_e^{after}$ $\leftarrow$ $(t_e+1)$ \COMMENT{at one week after}
\STATE $tp_{after}$ $\leftarrow$ $find\_tp(t_e^{after},r_e,t,r_v,tp)$

\STATE $tp\_final$ $\leftarrow$ $average(tp_{before}, tp_{at}, tp_{after})$
\IF{$tp\_final$ $<$ $0$}
\STATE $phase$ $\leftarrow$ $before$
\ELSIF{$tp\_final$ $==$ $0$}
\STATE $phase$ $\leftarrow$ $at$
\ELSE
\STATE $phase$ $\leftarrow$ $after$
\ENDIF
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Determine phase for the first access a requested video}
\label{alg3}
\begin{algorithmic}[1]
\REQUIRE {$t_e$ and time-to-peak distribution}

\STATE $len$ $\leftarrow$ 35 
\FOR{$i=0$ to $len$}
\STATE draw integer random number between $0$ and $35$ respect to time-to-peak distribution: 
$d$ $\leftarrow$ $draw\_integer\_random\_number()$
\ENDFOR

\STATE {$total \leftarrow 0$}
\FOR{$i=0$ to $t_e$}
\STATE $total$ $\leftarrow$ $total$ + $count(d,i)$ \COMMENT{counting how many each integer random number and sum those}
\ENDFOR
\STATE{$estphase$ $\leftarrow$ $total/36$}
\IF{$estphase$ $>$ $0.75$}
\STATE {phase $\leftarrow$ after-peak}
\ELSIF{$estphase \leq 0.75$ and $estphase > 0.5$}
\STATE {phase $\leftarrow$ at-peak}
\ELSE
\STATE {phase $\leftarrow$ before-peak}
\ENDIF
\end{algorithmic}
\end{algorithm}


In determining the phase of a requested video $e$ with known age $t_e$ and view rate $r_e$ at $t_e$, we find the three $r_v$ data points whose rates are closest to $r_e$ at $t_e$, $(t_e - 1)$, and $(t_e + 1)$, and then average the $tp$ of the three data points.
The phase of the requested video $e$ is estimated to be before-peak, at-peak, or after-peak based on whether the average is negative, $0$, or positive.
The view rate $r_e$ of a video is calculated by substracting the view counts at the time of the current and the previous video requests.
The pseudo code for averaging the $tp$ is shown in algorithm \ref{alg2}.
%The view rate $r_e$  of a video is calculated using the view counts at the time of the current and the previous video requests.
But when a video is being requested for the first time, the phase can only be estimated using the age of the video.
In this case, we draw 36 random integer numbers $s_i$, $0 <= i <= 35$,  using the time-to-peak distribution in fig.~\ref{fig:timetopeak} then calculate the count of each integers between $0$ and $t_e$ from the drawn numbers then divide the result by 36, 
%i.e., $estphase = \sum$ of $0 <= i <= t_e$ , $count(i, s)/36$.
i.e., $estphase = \sum_{0}^{t_e} \frac{count(i,s)}{36}$.
The number 36 come from the duration of measurement and each week has its own probability as we shown in fig.~\ref{fig:timetopeak}.
%This result represents the estimated phase, where $estphase \leq 0.5$ the phase is before-peak; if $0.5 < estphase \leq 0.75$ the phase is at peak, and $estphase > 0.75$ is after-peak.
%From fig.~\ref{fig:timetopeak} since from first week until sixth week the time 
This result represents the estimated phase. 
From time to peak distribution, $50\%$ of video reach peak within four weeks. 
At that level, we expect that half of videos may reach at-peak and half of videos are not yet reach at-peak.
Therefore we put $0.5$ as low threshold.  
Still from the same time to peak distribution $75\%$ of video reach peak within six weeks, and beyond six week the distribution is considered, it means there are not much additional view count. 
In other words, beyond six weeks we consider videos reach after-peak phase. 
Therefore we put $0.75$ as high threshold.
The pseudo code for this purpose is shown in algorithm \ref{alg3}.


\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.6]{../../hindawi/graphs/p2p-system-description.eps}
\end{center}
\caption{Peer interaction in simulator.
When a peer requests a video, it always goes to a CDN server (step 1). 
The CDN provides the videos to the peer (step 2). 
If there is another peer request same video, that request will go to CDN (step 3).  
A CDN will check its record to see if there is some peers cache that requested video.  
If there is some peers cache that requested video, a CDN will reply with redirect message that asking a peer to download requested video from other peer (step 4).
If there s no peers have requested video, a CDN will serve the video.   
A peer then can request the video to other peer and get the video (step 5 and step 6).
}
\label{fig:p2pcdninteractioninsimulator}
\end{figure} 





\section{System Description}\label{systemdescription}
\subsection{System Overview}\label{systemoverview}
The main components of the system are: (1) CDN and (2) peers which are self organized into a P2P overlay network.
%CDN itself consist of edge servers that deliver the videos and control plane servers that coordinate or control between the peers and record peers activities.
%The recording peers activities function is basically maintain a database of which videos are currently available on which peers as well as details about the connectivity of these peers.
%Peers appear in control plane database when uploading a video, a peer has a video to share, and a peer delete a video in its cache.
%In current peer-assisted CDN practice, the videos and their corresponding indices are decoupled.
%In other words, they are maintained by control plane servers.
Each peer in the system has two functionalities.
First, a peer is a client that requests a video. 
Second, a peer is a contributor or share the cached video with other peers in the system. 
Peers control the number and utilization of their connection based on current resources availability.
In fig.\ref{fig:p2pcdninteractioninsimulator}, we describe the process of a peer that requests a video which derived from PROP.
When a video is requested for the first time, the CDN is resposible to deliver the requested video.
When a CDN receives a query for a same video, a CDN will find suitable peers that currently have a copy of a requested video.
The CDN then returns information about these peers to the querying peer.
%In our system, the videos and their corresponding indices are decoupled because in current modern commercial peer-assisted CDN, CDN is responsible for recording each peer activities.  


\subsection{Peer caching strategy}\label{peercachingstrategy}
Since we only discuss peer-to-peer side, the caching strategy used in the CDN is out of scope for this project. 
For the peer replacement strategy, we introduce \textit{utility function} of a video as:
\begin{equation}
u = \frac{ (f(p) - f(p_{min})) (f(p_{max}) - f(p)) }{r^{\alpha + \beta}} + z(t)
\end{equation}
where the first term is the utility function from PROP and $z$ is the additional factor from our model. 
$p$ represents the popularity of the video, $p_{min}$ represents minimum popularity in the system, , $p_{max}$ represents maximum popularity in the system, and $r$ represents number of video replica.
Following \cite{1613869}, we can calculate $p$ as follows:
\begin{equation}
p = min \left(\frac{n_i^r}{t_i^r - t_a^i}  , \frac{1}{t_{cur} - t_i^r}\right)
\end{equation}
Where $n_i^r$ is number of requested video, $t_i^r$ is last time the video is requested, $t_a^i$ is the uploaded time of the video, and $t_{cur}$ is the current time.
To able to track the simulation, we use default value from PROP thus we refer the readers to \cite{1613869} for the details.

The utility function reflects the popularity of a video in the system that considering number of copy of its video or replica. 
$u$ value itself lies in interval $[0,2]$ Guo et al.,\cite{1613869}.
We choose video with the smallest utility value as the candidate to be replaced when a peer's cache is full.
Since we can determine before-peak phase, at-peak phase, and after-peak phase of video, we modified the original utility function from PROP above by adding a $z(t)$ factor as follows:

\begin{equation}
 z(t) = 
  \begin{cases}
   0.15 & \text{if phase estimation is before-peak} \\
   0.47 & \text{if phase estimation is at-peak} \\
   0.38 & \text{if phase estimation is after-peak}
  \end{cases}
\end{equation}\label{eq:zfactor}


$z(t)$ is proportion of view count in before-peak, at-peak, and after-peak to the total view count that we get from Youtube datasets.  
Because from transformed Youtube dataset we already have before-peak, at-peak, and after-peak phase for each video, we can also calculate how many view count in before-peak phase, at-peak phase, and after-peak phase.  
However at-peak happens only one week and its view count proportion to the total view count relatively small.
On the other side, we want to emphasize peer caching of a video during at-peak phase thus proportion of view count of at-peak phase to the total view count is count from $at-peak week - 1$ until $(at-peak week + 1)$. 
Next we can count proportion of view count of before-peak and after-peak to the total view count.
The numbers of view count proportion the the total is shown in eq.\ref{eq:zfactor}.
The value of $z(t)$ is assigned after we finish to determine a video popopularity phase.  
For example: if we determine a video popularity phase is at-peak, then we assign $z(t)=0.47$.
%To able to track the simulation, we use default value from PROP thus we refer the readers to \cite{1613869}.
%$p$ represents popularity of the video, $p_{min}$ represents estimation of minimum popularity in P2P system, $p_{max}$ represents estimation of maximum popularity in P2P system, $r$ represents the number of replicas of the video in the system, and $f(p)$ is monotonic non-decreasing function.
%$\alpha$ and $\beta$ are the adjustment factor.
%The CDN can calculate $p_{min}$ and $p_{max}$ then propagate to the P2P system.
%To able to track the simulation, we use default value from PROP for $\alpha=\beta=1$ and $f(p)=log (p)$.
%We choose the video with the smallest $u$ value as the candidate to be replaced when a peer's cache capacity is full.
In PROP's utility function, the difference between very popular videos and unpopular video is very difficult to differentiate. 
For an unpopular video, $f(p)$ will be very close to $f(p_{min})$ thus $f(p) - f(p_{min})$ will be very close to $0$ then the utility function becomes very small.
For a very popular video, $f(p)$ will be very close to $f(p_{max})$, thus $f(p_{max}) - f(p)$ will be very close to $0$ and the  utility function becomes very small.  
Linear addition of $z(t)$ factor can help to differentiate the value of utility function.
%We summarize peer's decision for caching in pseudo code \ref{alg6}.

% \begin{algorithm}
% \caption{Peer decision}
% \label{alg6}
% \begin{algorithmic}[1]
% \REQUIRE a requested video popularity phase
% \STATE{calculate $p_{request}$ for a requested video}
% \IF{$phase$ $==$ $before$}
% \STATE{$z$ $\leftarrow$ $0.15$}
% \ELSIF{$phase$ $==$ $at$}
% \STATE{$z$ $\leftarrow$ $0.47$}
% \ELSE
% \STATE{$z$ $\leftarrow$ $0.38$}
% \ENDIF
% \STATE{get $p_{min}$ from CDN}
% \STATE{get $p_{max}$ from CDN}
% \STATE{get $r$ from CDN}
% \STATE{$u_{request}$ $\leftarrow$ $\frac{ (f(p_{request}) - f(p_{min})) (f(p_{max}) - f(p_{request})) }{r^{\alpha + \beta}} + z(t) $} \COMMENT{calculate u for a requested video}
% \FOR{every video inside peer's cache}\COMMENT{calculate $p$ and $u$ for every video inside peer's cache}
% \STATE{calculate $p$}
% \STATE{determine video popularity $phase$}
% \STATE{assign $z$ value}
% \STATE{get $r$ from CDN}
% \STATE{$u$ $\leftarrow$ $\frac{ (f(p) - f(p_{min})) (f(p_{max}) - f(p)) }{r^{\alpha + \beta}} + z(t)$ } \COMMENT{calculate u for a video inside peer's cache}
% \ENDFOR
% \STATE{$u_{min} \leftarrow min(u)$}
% \IF{$u_{request} > u_{min}$ }
% \IF{space not available}
% \STATE{delete video with $u_{min}$ inside peer's cache}
% \STATE{cache a requested video}
% \ELSE
% \STATE{cache a requested video}
% \ENDIF
% \ELSE
% \STATE{do not cache a requested video}
% \ENDIF
% \end{algorithmic}
% \end{algorithm}




\section{Evaluation}\label{evaluation}
%apa yng dievaluasi.
%bandingkan 2 proposal ini dng 2 metric yng ada misalnya.
%kenapa 2 metric ini dipilih.
%bagaimana evaluasinya:  bikin simulator: a, b, c ,d 
In order to evaluate the proposed peer-caching strategy using estimation of before-peak, at-peak, and after-peak information from Youtube VoD view model, we have to compare our model to PROP model.
We evaluate three metrics, which are peer contribution to delivery contents during simulation,  access frequency of cache during simulation, and number of replicas. 
Peer contribution metric related to byte-hit-ratio. 
Byte-hit-ratio is defined as the total bytes contents served by peers normalized by the total bytes of video all peers and CDN consume.
It means more peer contributions, more byte-hit-ratio because peer can get content from another peers. 
Access frequency of cache reflects the storage utilization. 
More access means more peer storage utilization.  
Number of replicas is also related to peer storage utilization.  
However, too many replicas will waste the storage resources.
To evaluate these metrics, we developed a peer-assisted CDN simulator. 


\subsection{Simulation Design}\label{simulationdesign}
An event driven simulator is developed using Python for this purpose.
In fig.\ref{fig:p2pcdninteractioninsimulator}, we describe the process of a peer that requests a video in simulator, which derived from PROP.
A peer and a CDN are implemented in object oriented-model inside the simulator. 
In short, a peer always requests to CDN then CDN will decided if a requested video is available in other peers or not. 
If a requested video is available in other peers, CDN will redirect the request to other peers.
If a requested video is not available CDN will serve the request.
%When a peer requests a video, it always goes to a CDN server (step 1). 
%The CDN provides the videos to the peer (step 2). 
%If there is another peer request same video, that request will go to CDN (step 3).  
%A CDN will check its record to see if there are some peers cache that requested video.  
%If there are some peers cache that requested video, a CDN will reply with redirect message that asking a peer to download requested video from other peer (step 4).
%If there are no peers have requested video, a CDN will serve the video.   
%A peer then can request the video to other peer and get the video (step 5 and step 6).
%From above description, we can see that deploying peer-assisted CDN can save some traffic since the clients which form P2P network can sharing the contents or videos.


\subsubsection{Catalog Generator}\label{catalog}
The goal for catalog generator is to create a catalog video that consist video-id, time when a video is uploaded, a video size, view count terminus, and progress of videos popularity like Youtube service model. 
We assume that a video is uploaded to server following Poisson process with mean rate $\lambda=1$ thus we can get the time when a video is uploaded. 
The view count terminus for every video is assigned randomly uniform from Youtube datasets and video size for every video is assigned randomly uniform between $1$ and $200$MB. 
Because very weak relationship between file size and popularity \cite{abhari2010workload} and our work much focus on popularity aspect impact to utility function rather than storage optimization, we believe that assigned random uniform file size from Youtube datasets does not have effect to our results. 
Finally, we have a catalog that consists of: video-id, time when a video is uploaded, view count terminus, and video size.

\subsubsection{Peer Request Generator}\label{peerrequest}
In catalog generator, we assume peer request a video to CDN following Poisson process with a mean rate $\lambda=1$ \cite{Zink:2009:CYN:1502814.1502987}.
There are three scenarios for peer request (named as scenario A, B, and C):
In scenario A, a peer chooses a video that has popularity following Youtube.
The objective of the first scenario, we want to see the peer requests effect to peer-assisted CDN when the request following Youtube popularity. 
In scenario B, a peer chooses a video that has popularity following Youtube but we shift the request four weeks later.  
The objective of the second scenario, we want to see the peer requests effect to peer-assisted CDN when the request from peers are lag four weeks after popular in Youtube.
In scenario C, a peer chooses a video that has popularity following zipf distribution with rate$=0.9$ \cite{6654887} thus a peer choose a video that its popularity does not follow Youtube popularity.
The objective of the third scenario, we want to see the peer request effect to peer-assisted CDN when the requests from peers are totally different from Youtube's videos popularity.

\subsubsection{Simulation Parameters and Scenarios}
The simulation parameters are follows:

\begin{itemize}
\item Length: $360$ days.
\item Video size: uniform random between $1$MB and $200$MB.
\item Peer capacity: $500$MB.
\item CDN capacity: $10000$MB.
\item Number of peers: $100000$.
\item Number of videos: $10000$.
\end{itemize}
Finally, we compare our results to original PROP \cite{1613869} implementation.

%There are three scenarios in our simulations.
%First, peers choose a video that has a popularity following from Youtube data sets that we already explained in \ref{catalog}.
%Second, peers choose a video that has a popularity following from Youtube data sets and we shift the requests time four weeks.
%Third, peers choose a video that has a popularity following zipf distribution with rate$=0.9$ \cite{6654887}.
%We compare our results to original PROP \cite{1613869} implementation.





%%%%%%%%%%%%%%%%%%%%%%%%% FIGURE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%contribution 
\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/repl/contributioncdnpeermodelsortedabs.eps}
\end{center}
\caption{Absolute of contribution of peer for scenario A ($y$-axis in log-scale).}
\label{fig:contrib-normal}
\end{figure}


\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/shift/contributioncdnpeermodelsortedabs.eps}
\end{center}
\caption{Absolute of contribution of peer for scenario B ($y$-axis in log-scale).}
\label{fig:contrib-shift}
\end{figure}


\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/zipf/contributioncdnpeermodelsortedabs.eps}
\end{center}
\caption{Absolute of contribution of peer for scenario C ($y$-axis in log-scale).}
\label{fig:contrib-zipf}
\end{figure}




%%%%%%%%%%%%%%%%%%%%%%%%% FIGURE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%replica

\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/repl/atd.eps}
\end{center}
\caption{Number of a video replicas when a peer request a video for scenario A ($y$ axis in log-scale).}
\label{fig:atd-normal}
\end{figure}

\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/shift/atd.eps}
\end{center}
\caption{Number of a video replicas when a peer request a video for scenario B ($y$ axis in log-scale).}
\label{fig:atd-shift}
\end{figure}

\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/zipf/atd.eps}
\end{center}
\caption{Number of a video replicas when a peer request a video for scenario C ($y$ axis in log-scale). In model we found many zero replica when a peer requests a video. Because we use log-scale in this figure, the zero numbers can not be viewed. }
\label{fig:atd-zipf}
\end{figure}



\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/repl/freq.eps}
\end{center}
\caption{Frequency a video stays in peers for scenario A.}
\label{fig:freq-normal}
\end{figure}


\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/shift/freq.eps}
\end{center}
\caption{Frequency a video stays in peers for scenario B.}
\label{fig:freq-shift}
\end{figure}


\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/zipf/freq.eps}
\end{center}
\caption{Frequency a video stays in peers for scenario C.}
\label{fig:freq-zipf}
\end{figure}




\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/repl/duration.eps}
\end{center}
\caption{Cache duration of a video in peers for scenario A.}
\label{fig:duration-normal}
\end{figure}

\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/shift/duration.eps}
\end{center}
\caption{Cache duration of a video in peers for scenario B.}
\label{fig:duration-shift}
\end{figure}

\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/zipf/duration.eps}
\end{center}
\caption{Cache duration of a video in peers for scenario C.}
\label{fig:duration-zipf}
\end{figure}


\subsection{Result and Discussion}\label{resultanddiscussion}
Figure \ref{fig:contrib-normal}, \ref{fig:contrib-shift}, and \ref{fig:contrib-zipf} show the absolute peer contribution to deliver videos compared between model and prop. 
Figure \ref{fig:contrib-normal} and fig.\ref{fig:contrib-shift} show same pattern.
The peers give more contribution in the tail while in the third scenario the peer contribution is mostly same between model and PROP. 
A peers can give more contribution because a video has longer duration than other videos in a peer's cache thus other peer's requests are served by the peer. 
A video has longer duration than other videos in peer's cache because that a video has bigger utility function than other videos for example a video that will enter the cache. 

\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
\caption{Percentage of Cached events and Not-Cached events in Model and PROP}
\label{tab:stacked1}
\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
\begin{tabular}{|l|l|c|c|}
\hline
Scenario & Type & Cached & Not-Cached\\
\hline
Scenario 1 & Model & $33.5\%$ & $66.5\%$ \\
\hline
 & PROP & $52\%$ & $48\%$  \\
\hline

Scenario 2 & Model & $34.8\%$ & $65.2\%$ \\
\hline
 & PROP & $52.6\%$ & $47.4\%$  \\
\hline

Scenario 3 & Model & $32.4\%$ & $67.6\%$  \\
\hline
 & PROP & $67.7\%$ & $32.3\%$ \\
\hline
\end{tabular}
\end{table}

Figure \ref{fig:atd-normal}, \ref{fig:atd-shift}, and \ref{fig:atd-normal} show the number of  videos replicas available in system when a peer requests a video.
As we can see from all figures, the model gives us lower number of replicas than PROP.
The model gives lower number of replicas than PROP because when a peer requests a video, that peer is not cached the video.
We can see the proportion of cached and not-cached event in table.\ref{tab:stacked1}. 
We also present detail of the video phase breakdown in table.\ref{tab:stacked2}.
In model, not-cached events take around $65\%$ from all events and majority of video phase is  after-peak for both cached events and not-cached events. 
Because the majority of video phase is  after-peak for both cached events and not-cached events, 
In PROP, cached events take around $52\%$ from all events for the first scenario and the second scenario, while for the third scenario is $67.7\%$.
In model not-cached events are bigger than PROP, means peers do not cached the videos thus we get lower replicas number than PROP.


Denote $u_{dl}$ is the minimum utility function for a video inside the cache and $u_{ms}$ is utility function for a video that will enter the cache,  $p_{dl}$ is the popularity for a video inside the cache and $p_{ms}$ is the popularity for a video that will enter the cache.
In order a requested video is cached by a peer, the utility function for $u_{dl}$ must be lower than the utility function for $u_{ms}$.

\begin{align}\label{eq:dlms_1}
u_{dl} < u_{ms}
\end{align}

\begin{multline}\label{eq:dlms_2}
\frac{ (f(p_{dl}) - f(p_{min})) (f(p_{max}) - f(p_{dl})) }{r^{\alpha + \beta}_{dl}} + z_{dl} < \\
\frac{ (f(p_{ms}) - f(p_{min})) (f(p_{max}) - f(p_{ms})) }{r^{\alpha + \beta}_{ms}} + z_{ms}
%\end{equation}
\end{multline}

We assume that numbers of replicas are same, thus:
\begin{multline}\label{eq:dlms_3}
(f(p_{dl}) - f(p_{min})) (f(p_{max}) - f(p_{dl})) - \\ 
(f(p_{ms}) - f(p_{min})) (f(p_{max}) - f(p_{ms})) < \\
z_{ms} - z_{dl}
\end{multline}

Since $p_{min}$ and $p_{max}$ are same for $u_{dl}$ and $u_{ms}$, we can arrange the equation become:
\begin{align}\label{eq:dlms_4}
f(p_{ms}) - f(p_{dl}) > z_{dl} - z_{ms}
\end{align}

%comparing with PROP, we can get: 
%\begin{align}\label{eq:dlms_5}
%f(p_{ms}) - f(p_{dl}) > 0 \\
%f(p_{ms}) - f(p_{dl}) > z_{dl} - z_{ms}
%\end{align}

As we know from table.\ref{tab:stacked2} that the majority of a requested video is after-peak phase and a requested video phase that is  at-peak phase is very small portion, then we can see that $z_{dl} - z_{ms}$ term will be in negative term if $z_{dl}$ is  before-peak phase or $0$ if $z_{dl}$ is  after-peak phase. 
If $z_{dl} - z_{ms}=0$ then it is same with PROP. 
Since the not-cached events happen in when a requested video phase after-peak phase, we can get that $f(p_{ms}) - f(p_{dl}) < 0$.
For the same situation and we compare to the PROP, the probability of $u_{ms}$ less than $u_{dl}$ in the model is less than PROP. 
Therefore, we can see in the model that the events when a peer does not cache a video are more often than PROP.

\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
\caption{Percentage of Video Phase for Model in cached and not-cached events}
\label{tab:stacked2}
\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
\begin{tabular}{|l|l|c|c|c|}
\hline
Scenario & Type/Events & Before-Peak & At-Peak & After-Peak\\
\hline
Scenario 1 & Model-Cached & $8.2\%$ & $1.2\%$ & $24.1\%$ \\
\hline
 & Model-Not-Cached & $11.2\%$ & $0.8\%$ & $54.5\%$ \\
 \hline

Scenario 2 & Model-Cached & $6.2\%$ & $1.2\%$ & $29.8\%$ \\
\hline
 & Model-Not-Cached & $5.2\%$ & $0.8\%$ & $56.8\%$ \\
\hline

Scenario 3 & Model-Cached & $8.0\%$ & $1.8\%$ & $22.7\%$ \\
\hline
 & Model-Not-Cached & $15.1\%$ & $0.8\%$ & $51.6\%$ \\
\hline
\end{tabular}
\end{table}

Figure \ref{fig:freq-normal}, \ref{fig:freq-shift}, and \ref{fig:freq-zipf} show the frequency of a video stay in peers compared between model and PROP.
As all figure show the model has higher frequency than PROP to stay in peers except for the beginning rank of data where the model has same frequency with prop in first and second scenario. 
In the third scenario, in the beginning rank of data the model has lower frequency than PROP, then around rank 1000 the model has higher frequency than prop until the end of data. 
The frequency a video stay in a video can also be viewed in fig \ref{fig:duration-normal},  \ref{fig:duration-shift}, and \ref{fig:duration-zipf}, where in the model some videos have longer cache duration than PROP, while others have shorter cache duration than PROP.  
Thus, we can see the relationship between cache duration and frequency a video stays in peers. 


\section{Summary}
This chapter presents a scheme for peer-to-peer network can help CDN to deliver the content over the Internet. 
We show that by introducing $z$ factor to utility function we can maintain same peer contribution while reducing number of replicas.
We found that there are no much different between the first scenario, the second scenario and the third scenario in peer contribution to deliver a video. 
We found that in the all scenarios, the model gives lower replicas than PROP. 
This is because in the model, we found that not-cached events are higher than cached events, more specifically, the probability of utility function a requested video in model is lower than PROP.
Therefore, in the model the numbers of available replicas are lower than PROP. 
We also did the significance test to the number of replicas using the Kolmogorov-Smirnov statistic on two samples and we find that for all scenarios the $p$-values are less than $1$\% thus the results are significant. 

Some areas of improvement that we have identified for future are:
The energy trade off this peer-assisted CDN architecture in order to know how much energy saving by ISP and how much increase of energy at users home gateway side in this architecture since we have higher peer contribution.   
More numerical experiments for other zipf shape parameters. 



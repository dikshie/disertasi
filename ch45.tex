\chapter{Peer-Assisted Content Delivery}

\section{Introduction}

Streaming content, especially video, represents a significant fraction of the traffic volume on the Internet, and it has become a standard practice to deliver this type of content using Content Delivery Networks (CDNs) such as Akamai and Limelight for better scaling and quality of experience for the end users. 
For example, YouTube uses Google cache and MTV uses Akamai in their operations.

With the spread of broadband Internet access at a reasonable flat monthly rate, users are connected to the Internet 24 hours a day and they can download and share multimedia content. P2P (peer to peer) applications are also widely deployed. 
In China, P2P is very popular; we see many P2P applications from China such as PPLive, PPStream, UUSe, Xunlei, etc. \cite{Vu:2010:UOC:1865106.1865115}. 
Some news broadcasters also rely on P2P technology to deliver popular live events. 
For example, CNN uses the Octoshape \cite{octoshape} solution that enables their broadcast to scale and offer good video quality as the number of users increases.

From the Internet provider point of view, the presence of so many always-on users suggests that it is possible to delegate a portion of computing, storage and networking tasks to the users, thus creating P2P networks where users can share files and multimedia content. 
Starting from file sharing protocols, P2P architectures have evolved toward video on demand and support for live events.

%A P2P based architecture usually requires a sufficient number of nodes supplying the data (seeders) to start the distribution process among the joining peers.  
%A peer usually offers a low outbound streaming rate due to the traditional asymmetrical DSL home connectivity and hence multiple peers must jointly stream contents to a requesting peer (leecher).  
%The decentralized, uncoordinated operation implies that scaling to a high number of peers comes with side effects.  
%Typical problems of a P2P streaming architecture are low stream quality with undesirable disruptions, resource unfairness due to heterogeneous peer resources, and high startup delay.  
%Moreover, current P2P applications are not aware of the underlying network and may conflict with the ISP routing policies and business model.

%A number of P2P streaming applications have been designed, analyzed and deployed, attracting a significant number of users.  
%Research studies and deployment experiences have both demonstrated that P2P is a promising solution in terms of scalability and deployment costs.  
%On the other hand, the heterogeneous nature and unstable behavior of the peers contributing bandwidth and computational resources, along with the networking issues, affect the user experience and limit the commercial success of P2P video streaming applications.
Alternatively, video contents can be efficiently distributed on services offered by managed network architectures and CDN companies.
The major issues of CDN are high deployment cost and good but not unlimited scalability in the long term.  
Given the complementary features of P2P and CDN, in recent years some hybrid solutions have been proposed and applied to the operational of CDN \cite{Huang:2008:UHC:1496046.1496064,4772628,Yin:2009:DDH:1631272.1631279} to take the best of both approaches.
In Peer assisted CDN, users can download content from CDN nodes from or other users or peers. 
A user may cache the content after download to serve requests from other users. 
Due to the complexity of the behavior of peers, the process should be done in the home gateway user where the ISP can control it.

In this work, we will revisit Guo et al.'s, \cite{1613869} PROP as a basis to evaluate peer-assisted CDN and propose an improvement to the model for the PROP called CPPro.
This system is called CPPro abbreviated from out technical term "CDN-P2P Project".
We will take Youtube as an example of an Internet VoD service model.
In the Youtube service model, we can get data such as (1) the time when a video is uploaded and (2) number of access or number of view.
We can get such data using Youtube's API.
In seminal work, Borghol et al., \cite{Borghol:2011:CMP:2039452.2039717} used the above information to estimate when a video will become very popular.
They divide a video's popularity into three phases: before-peak phase, at-peak phase, and after-peak phase.
We will use an estimate of a video's popularity phases for helping PROP.
We will explain video popularity in Sec.\ref{popularity}.
Our contribution is as follows:
(1) We use the idea of VoD view popularity model to aid the PROP model. 
To the best of our knowledge, the combination of the PROP model and the VoD view popularity model is new.
(2) From simulation-based experiments, we find that peer contributions in CPPro are almost as good as  PROP while the numbers of replicas are lower than PROP resulting in a reduction of resources required.




%%related work pindah ke chapter 2

\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/timetopeak.eps}
\end{center}
\caption{Time to peak empirical distribution data from \cite{Borghol:2011:CMP:2039452.2039717}.}
\label{fig:timetopeak}
\end{figure} 

\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/datadistribution.eps}
\end{center}
\caption{View rate distribution versus week relative to at-peak phase week for every video in Youtube datasets, where y-axis in log scale.
We shift the week relative to to at-peak phase week.
Every point lies in negative x-axis mean view rate of every video in before-peak phase.
Every point lies in x-axis$=0$ mean view rate of every video at-peak phase. 
Every point lies in positive x-axis mean view rate of every video in after-peak phase.
Data from \cite{Borghol:2011:CMP:2039452.2039717}.
}
\label{fig:viewratedistribution}
\end{figure} 


\section{Determining Internet VoD Popularity Phase}\label{popularity}

The objective of determining the Internet VoD popularity phase is to determine whether a video is at before-peak, at-peak, or after-peak phase, to be used by peers in their caching strategy.
For this purpose we use the Youtube content popularity dataset from Borghol et. al.,\cite{Borghol:2011:CMP:2039452.2039717}  which contains the data of 29791 videos, including the view count and upload time, during 36 weeks of measurements.
Figure~\ref{fig:timetopeak} is cummulative distribution function (CDF) the time-to-peak distribution from Borghol et. al.,\cite{Borghol:2011:CMP:2039452.2039717}  which shows that around three-quarters of the videos peak within the first six weeks after upload.
The time-to-peak is exponentially distributed up-to the sixth week, and it is uniform beyond the sixth week.
Borghol et al., \cite{Borghol:2011:CMP:2039452.2039717} define time-to-peak for a video as its age (time since upload) at which its weekly viewing rate is the highest during measurement (from the first week until end of measurement).
Because we know the peak time (at-peak phase) of every video, we can also find the before-peak phase and after-phase of every video. 
For detail we refer the readers to \cite{Borghol:2011:CMP:2039452.2039717}.

Suppose a video $v$ in Borghol dataset has a viewing rate $r_v(t)$, $0 <= t < t_f$, and $r_v(t)$ peaks at $t_{vp}$.
The data is transformed by including the relative time-to-peak, such that each data point is a 2-tuple: video rate and relative time to peak, i.e., $rp_v(t) = ( r_v(t), tp(t) ), tp(t) = t - t_{vp}$.
Figure~\ref{fig:viewratedistribution} shows the Borghol's dataset with time axis for each video is translated by $t_{vp}$ to the left, such that each video peaks at time $0$.

% \begin{figure}[!t]
% \begin{center}
% \includegraphics[scale=0.7]{../../hindawi/graphs/transformasi.eps}
% \end{center}
% \caption{Transformation of view rate distribution. We add week number and make it as $x$-axis, View rate as $y$-axis, and relative week to peak as $z$-axis.}
% \label{fig:viewratedistexample}
% \end{figure} 

% \begin{figure}[!t]
% \begin{center}
% \includegraphics[scale=0.7]{../../hindawi/graphs/transformasi3.eps}
% \end{center}
% \caption{2D visualization of view rate distribution after transformation where $x$-axis is week number, $y$-axis is view rate.}
% \label{fig:viewratedistexamplered}
% \end{figure} 

\begin{algorithm}
\caption{Averaging relative weeks from the nearest neighbor points}
\label{alg2}
\begin{algorithmic}[1]
\REQUIRE {dataset that consist of weeknumber, viewrate, and relative week to at peak.}

\STATE $t$ $\leftarrow$ read(weeknumber) \COMMENT{read week number from dataset}
\STATE $r_v$ $\leftarrow$ read(viewrate) \COMMENT{read view rate from dataset}
\STATE $tp$ $\leftarrow$ read(relativeweeksatpeak) \COMMENT{read relative week at peak from dataset}

%\COMMENT{a requested video has week number and view rate}
\STATE $t_e$ \COMMENT{week number of a requested video}
\STATE $r_e$ \COMMENT{view rate of a requested video}

\STATE $t_e^{before}$ $\leftarrow$ $(t_e - 1)$ \COMMENT{at one week before}
\STATE $tp_{before}$ $\leftarrow$ $find\_tp(t_e^{before},r_e,t,r_v,tp)$

\STATE $t_e^{at}$ $\leftarrow$ $(t_e)$ \COMMENT{at same week}
\STATE $tp_{at}$ $\leftarrow$ $find\_tp(t_e^{at},r_e,t,r_v,tp)$

\STATE $t_e^{after}$ $\leftarrow$ $(t_e+1)$ \COMMENT{at one week after}
\STATE $tp_{after}$ $\leftarrow$ $find\_tp(t_e^{after},r_e,t,r_v,tp)$

\STATE $tp\_final$ $\leftarrow$ $average(tp_{before}, tp_{at}, tp_{after})$
\IF{$tp\_final$ $<$ $0$}
\STATE $phase$ $\leftarrow$ $before$
\ELSIF{$tp\_final$ $==$ $0$}
\STATE $phase$ $\leftarrow$ $at$
\ELSE
\STATE $phase$ $\leftarrow$ $after$
\ENDIF
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Determine phase for the first access a requested video}
\label{alg3}
\begin{algorithmic}[1]
\REQUIRE {$t_e$ and time-to-peak distribution}

\STATE $len$ $\leftarrow$ 35 
\FOR{$i=0$ to $len$}
\STATE draw integer random number between $0$ and $35$ respect to time-to-peak distribution: 
$d$ $\leftarrow$ $draw\_integer\_random\_number()$
\ENDFOR

\STATE {$total \leftarrow 0$}
\FOR{$i=0$ to $t_e$}
\STATE $total$ $\leftarrow$ $total$ + $count(d,i)$ \COMMENT{counting how many each integer random number and sum those}
\ENDFOR
\STATE{$estphase$ $\leftarrow$ $total/36$}
\IF{$estphase$ $>$ $0.75$}
\STATE {phase $\leftarrow$ after-peak}
\ELSIF{$estphase \leq 0.75$ and $estphase > 0.5$}
\STATE {phase $\leftarrow$ at-peak}
\ELSE
\STATE {phase $\leftarrow$ before-peak}
\ENDIF
\end{algorithmic}
\end{algorithm}




In determining the phase of a requested video $e$ with known age $t_e$ and view rate $r_e$ at $t_e$, we find the three $r_v$ data points whose rates are closest to $r_e$ at $t_e$, $(t_e - 1)$, and $(t_e + 1)$, and then average the $tp$ of the three data points.
The phase of the requested video $e$ is estimated to be before-peak, at-peak, or after-peak based on whether the average is negative, $0$, or positive.
The view rate $r_e$ of a video is calculated by substracting the view counts at the time of the current and the previous video requests.
The pseudo code for averaging the $tp$ is shown in algorithm \ref{alg2}.
%The view rate $r_e$  of a video is calculated using the view counts at the time of the current and the previous video requests.
But when a video is being requested for the first time, the phase can only be estimated using the age of the video.
In this case, we draw 36 random integer numbers $s_i$, $0 <= i <= 35$,  using the time-to-peak distribution in fig.~\ref{fig:timetopeak} then calculate the count of each integers between $0$ and $t_e$ from the drawn numbers then divide the result by 36, 
%i.e., $estphase = \sum$ of $0 <= i <= t_e$ , $count(i, s)/36$.
i.e., $estphase = \sum_{0}^{t_e} \frac{count(i,s)}{36}$.
The number 36 come from the duration of measurement and each week has its own probability as we shown in fig.~\ref{fig:timetopeak}.
%This result represents the estimated phase, where $estphase \leq 0.5$ the phase is before-peak; if $0.5 < estphase \leq 0.75$ the phase is at peak, and $estphase > 0.75$ is after-peak.
%From fig.~\ref{fig:timetopeak} since from first week until sixth week the time 
This result represents the estimated phase. 
From time to peak distribution, $50\%$ of video reach peak within four weeks. 
At that level, we expect that half of videos may reach at-peak and half of videos are not yet reach at-peak.
Therefore we put $0.5$ as low threshold.  
Still from the same time to peak distribution $75\%$ of video reach peak within six weeks, and beyond six week the distribution is considered, it means there are not much additional view count. 
In other words, beyond six weeks we consider videos reach after-peak phase. 
Therefore we put $0.75$ as high threshold.
The pseudo code for this purpose is shown in algorithm \ref{alg3}.


\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.6]{../../hindawi/graphs/p2p-system-description.eps}
\end{center}
\caption{Peer assisted CDN works as follows:
when a peer requests a video, it always goes to a CDN server (step 1). 
The CDN provides the videos to the peer (step 2). 
If there is another peer request same video, that request will go to CDN (step 3).  
A CDN will check its record to see if there is some peers cache that requested video.  
If there is some peers cache that requested video, a CDN will reply with redirect message that asking a peer to download requested video from other peer (step 4).
If there s no peers have requested video, a CDN will serve the video.   
A peer then can request the video to other peer and get the video (step 5 and step 6).
}
\label{fig:p2pcdninteractioninsimulator}
\end{figure} 





\section{System Description}\label{systemdescription}
\subsection{System Overview}\label{systemoverview}

The main components of the system are: (1) CDN and (2) peers which are self organized into a P2P overlay network.
%CDN itself consist of edge servers that deliver the videos and control plane servers that coordinate or control between the peers and record peers activities.
%The recording peers activities function is basically maintain a database of which videos are currently available on which peers as well as details about the connectivity of these peers.
%Peers appear in control plane database when uploading a video, a peer has a video to share, and a peer delete a video in its cache.
%In current peer-assisted CDN practice, the videos and their corresponding indices are decoupled.
%In other words, they are maintained by control plane servers.
Each peer in the system has two functionalities.
First, a peer is a client that requests a video. 
Second, a peer is a contributor or share the cached video with other peers in the system. 
Peers control the number and utilization of their connection based on current resources availability.
In fig.\ref{fig:p2pcdninteractioninsimulator}, we describe the process of a peer that requests a video which derived from PROP.
When a video is requested for the first time, the CDN is resposible to deliver the requested video.
When a CDN receives a query for a same video, a CDN will find suitable peers that currently have a copy of a requested video.
The CDN then returns information about these peers to the querying peer.
%In our system, the videos and their corresponding indices are decoupled because in current modern commercial peer-assisted CDN, CDN is responsible for recording each peer activities.  



\subsection{Peer caching strategy}\label{peercachingstrategy}

Since we only discuss peer-to-peer side, the caching strategy used in the CDN is out of scope for this project. 
For the peer replacement strategy, we introduce \textit{utility function} of a video as:
\begin{equation}
u = \frac{ (f(p) - f(p_{min})) (f(p_{max}) - f(p)) }{r^{\alpha + \beta}} + z(t)
\end{equation}
where the first term is the utility function from PROP and $z$ is the additional factor for CPPro. 
$p$ represents the popularity of the video, $p_{min}$ represents minimum popularity in the system, , $p_{max}$ represents maximum popularity in the system, and $r$ represents number of video replica.
Following \cite{1613869}, we can calculate $p$ as follows:
\begin{equation}
p = min \left(\frac{n_i^r}{t_i^r - t_a^i}  , \frac{1}{t_{cur} - t_i^r}\right)
\end{equation}
Where $n_i^r$ is number of requested video, $t_i^r$ is last time the video is requested, $t_a^i$ is the uploaded time of the video, and $t_{cur}$ is the current time.
To able to track the simulation, we use default value from PROP thus we refer the readers to \cite{1613869} for the details.

The utility function reflects the popularity of a video in the system that considering number of copy of its video or replica. 
$u$ value itself lies in interval $[0,2]$ Guo et al.,\cite{1613869}.
We choose video with the smallest utility value as the candidate to be replaced when a peer's cache is full.
Since we can determine before-peak phase, at-peak phase, and after-peak phase of video, we modified the original utility function from PROP above by adding a $z(t)$ factor as follows:



\begin{equation}
 z(t) = 
  \begin{cases}
   0.15 & \text{if phase estimation is before-peak} \\
   0.47 & \text{if phase estimation is at-peak} \\
   0.38 & \text{if phase estimation is after-peak}
  \end{cases}
\end{equation}\label{eq:zfactor}

$z(t)$ is proportion of view count in before-peak, at-peak, and after-peak to the total view count that we get from Youtube datasets.  
Because from transformed Youtube dataset we already have before-peak, at-peak, and after-peak phase for each video, we can also calculate how many view count in before-peak phase, at-peak phase, and after-peak phase.  
However at-peak happens only one week and its view count proportion to the total view count relatively small.
On the other side, we want to emphasize peer caching of a video during at-peak phase thus proportion of view count of at-peak phase to the total view count is count from one week before at-peak until one week after-peak.
Next we can count proportion of view count of before-peak and after-peak to the total view count.
The numbers of view count proportion for $z(t)$ is shown in eq.\ref{eq:zfactor}.

The value of $z(t)$ is assigned after we finish to determine a video popularity phase.  
For example: if we determine a video popularity phase is at-peak, then we assign $z(t)=0.47$.

%To able to track the simulation, we use default value from PROP thus we refer the readers to \cite{1613869}.
%$p$ represents popularity of the video, $p_{min}$ represents estimation of minimum popularity in P2P system, $p_{max}$ represents estimation of maximum popularity in P2P system, $r$ represents the number of replicas of the video in the system, and $f(p)$ is monotonic non-decreasing function.
%$\alpha$ and $\beta$ are the adjustment factor.
%The CDN can calculate $p_{min}$ and $p_{max}$ then propagate to the P2P system.
%To able to track the simulation, we use default value from PROP for $\alpha=\beta=1$ and $f(p)=log (p)$.
%We choose the video with the smallest $u$ value as the candidate to be replaced when a peer's cache capacity is full.
In PROP's utility function, the difference between very popular videos and unpopular video is very difficult to differentiate. 
For an unpopular video, $f(p)$ will be very close to $f(p_{min})$ thus $f(p) - f(p_{min})$ will be very close to $0$ then the utility function becomes very small.
For a very popular video, $f(p)$ will be very close to $f(p_{max})$, thus $f(p_{max}) - f(p)$ will be very close to $0$ and the  utility function becomes very small.  
Linear addition of $z(t)$ factor can help to differentiate the value of utility function.
%We summarize peer's decision for caching in pseudo code \ref{alg6}.

% \begin{algorithm}
% \caption{Peer decision}
% \label{alg6}
% \begin{algorithmic}[1]
% \REQUIRE a requested video popularity phase
% \STATE{calculate $p_{request}$ for a requested video}
% \IF{$phase$ $==$ $before$}
% \STATE{$z$ $\leftarrow$ $0.15$}
% \ELSIF{$phase$ $==$ $at$}
% \STATE{$z$ $\leftarrow$ $0.47$}
% \ELSE
% \STATE{$z$ $\leftarrow$ $0.38$}
% \ENDIF
% \STATE{get $p_{min}$ from CDN}
% \STATE{get $p_{max}$ from CDN}
% \STATE{get $r$ from CDN}
% \STATE{$u_{request}$ $\leftarrow$ $\frac{ (f(p_{request}) - f(p_{min})) (f(p_{max}) - f(p_{request})) }{r^{\alpha + \beta}} + z(t) $} \COMMENT{calculate u for a requested video}
% \FOR{every video inside peer's cache}\COMMENT{calculate $p$ and $u$ for every video inside peer's cache}
% \STATE{calculate $p$}
% \STATE{determine video popularity $phase$}
% \STATE{assign $z$ value}
% \STATE{get $r$ from CDN}
% \STATE{$u$ $\leftarrow$ $\frac{ (f(p) - f(p_{min})) (f(p_{max}) - f(p)) }{r^{\alpha + \beta}} + z(t)$ } \COMMENT{calculate u for a video inside peer's cache}
% \ENDFOR
% \STATE{$u_{min} \leftarrow min(u)$}
% \IF{$u_{request} > u_{min}$ }
% \IF{space not available}
% \STATE{delete video with $u_{min}$ inside peer's cache}
% \STATE{cache a requested video}
% \ELSE
% \STATE{cache a requested video}
% \ENDIF
% \ELSE
% \STATE{do not cache a requested video}
% \ENDIF
% \end{algorithmic}
% \end{algorithm}



\section{Evaluation}\label{evaluation}
In order to evaluate the proposed peer-caching strategy using our algoritmic designation of the poplarity phase of before-peak, at-peak, and after-peak information from Youtube VoD view model, we have to compare CPPro to the PROP model.
We evaluate three metrics, which are: (1) peer contribution to delivery contents during simulation,  access frequency of cache during simulation, and number of replicas. 
We define peer contribution as how many times a video is delivered by peer during simulation.
The peer contribution metric is related to the byte-hit-ratio. 
The byte-hit-ratio is defined as the total bytes of content served by peers normalized by the total bytes of video all peers and the CDN consume.
With more peer contributions, we will have higher byte-hit-ratio because peer can get content from other peers. 
However, because we only interested in peer performance, we compare peer contribution between PROP and CPPro.
Contribution ratio of peer to total contribution (comparing to CDN contribution) becomes irrelevant in this case.
(2) Access frequency of cache reflects the storage utilization. 
More access means more peer storage utilization.  
(3) Number of replicas is also related to peer storage utilization.  
However, too many replicas will waste the storage resources.
To evaluate these metrics, we developed a peer-assisted CDN simulator. 


\subsection{Simulation Design}\label{simulationdesign}
This peer-assisted CDN is simulated using an event driven simulation implemented in Python. 
Peers request videos from a video catalog where the peer request as well as the videos in the catalog are generated using certain distributions.

\subsubsection{Video Catalog}\label{catalog}
Each video in tha catalog has the following properties: 
video-id,size,upload time, final view count, view count function parameters. 
View count parameters are the distribution parameters.
The final view count is the total number of views of a video at the end of simulation and it is generated using uniform distribution.
Upload time interval is a Poisson process with $\lambda=1$.
Video size is generated using a uniform distribution.
Because of the very weak relationship betwen video size and popularity \cite{abhari2010workload} and because our work focuses on the impact of the popularity aspect on the utility function rather than storage optimization we believe that the choice to assign a random uniform video size from the Youtube dataset does not have an effect to our results. 
The view rate progression from the upload time until the end of simulation time is modelled using a Beta distribution \cite{Borghol:2011:CMP:2039452.2039717}.
As Borghol et al.,\cite{Borghol:2011:CMP:2039452.2039717} showed that view rate of a video can be modelled using beta distribution we can calculate $\alpha$ and $\beta$ parameters.
Since we have view rate at peak, we can use Beta distribution mode formula to calculate $\alpha$ or $\beta$. In this case, we choose $\alpha$ random uniform between $1$ and $3$, thus $\beta$ parameter can be calculated using mode formula.



\subsubsection{Peer Request Generator}\label{peerrequest}
Peers request videos from the catalog using a Poisson process with $\lambda=1$ \cite{Zink:2009:CYN:1502814.1502987} for the inter-arrival time.
For the requested videos there are three scenarios namely A,B,and C.
Scenario A is where the video popularity in the peer-assisted CDN system follows the global popularity of the video.
Scenario B is where the video popularity in the peer-assisted CDN system lagging four weeks behind the global popularity of the video. 
We choose four weeks based on probability from time-to-peak distribution that half of videos are already reach peak within four weeks.
Scenario C is where the video popularity in the peer-assisted CDN system does not follow the global popularity of the video. 
We use Zipf distribution with rate$=0.9$ for this purpose \cite{6654887}.

\subsubsection{Simulation Parameters}
The simulation parameters are follows:
\begin{itemize}
\item Length: $360$ days.
\item Video size: uniform random between $1$MB and $200$MB.
\item Peer storage capacity: $500$MB.
\item CDN storage capacity: $10000$MB.
\item Number of peers: $100000$.
\item Number of videos: $10000$.
\item Peer's caching strategy: CPPro, PROP.
\end{itemize}
Finally, we compare our results to PROP \cite{1613869} implementation.


%%%%%%%%%%%%%%%%%%%%%%%%% FIGURE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%contribution 
\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/repl/contributioncdnpeermodelsortedabs.eps}
\end{center}
\caption{Absolute of contribution of peer for scenario A ($y$-axis in log-scale).}
\label{fig:contrib-normal}
\end{figure}


\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/shift/contributioncdnpeermodelsortedabs.eps}
\end{center}
\caption{Absolute of contribution of peer for scenario B ($y$-axis in log-scale).}
\label{fig:contrib-shift}
\end{figure}


\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/zipf/contributioncdnpeermodelsortedabs.eps}
\end{center}
\caption{Absolute of contribution of peer for scenario C ($y$-axis in log-scale).}
\label{fig:contrib-zipf}
\end{figure}




%%%%%%%%%%%%%%%%%%%%%%%%% FIGURE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%replica

\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/repl/atd.eps}
\end{center}
\caption{Number of a video replicas when a peer request a video for scenario A ($y$ axis in log-scale).}
\label{fig:atd-normal}
\end{figure}

\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/shift/atd.eps}
\end{center}
\caption{Number of a video replicas when a peer request a video for scenario B ($y$ axis in log-scale).}
\label{fig:atd-shift}
\end{figure}

\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/zipf/atd.eps}
\end{center}
\caption{Number of a video replicas when a peer request a video for scenario C ($y$ axis in log-scale). In model we found many zero replica when a peer requests a video. Because we use log-scale in this figure, the zero numbers can not be viewed. }
\label{fig:atd-zipf}
\end{figure}



\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/repl/freq.eps}
\end{center}
\caption{Frequency a video stays in peers for scenario A.}
\label{fig:freq-normal}
\end{figure}


\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/shift/freq.eps}
\end{center}
\caption{Frequency a video stays in peers for scenario B.}
\label{fig:freq-shift}
\end{figure}


\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/zipf/freq.eps}
\end{center}
\caption{Frequency a video stays in peers for scenario C.}
\label{fig:freq-zipf}
\end{figure}




\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/repl/duration.eps}
\end{center}
\caption{Cache duration of a video in peers for scenario A.}
\label{fig:duration-normal}
\end{figure}

\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/shift/duration.eps}
\end{center}
\caption{Cache duration of a video in peers for scenario B.}
\label{fig:duration-shift}
\end{figure}

\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.7]{../../hindawi/graphs/new/zipf/duration.eps}
\end{center}
\caption{Cache duration of a video in peers for scenario C.}
\label{fig:duration-zipf}
\end{figure}


\subsection{Result and Discussion}\label{resultanddiscussion}

Figure~fig.~\ref{fig:contrib-normal}, \ref{fig:contrib-shift}, and \ref{fig:contrib-zipf}shows the peer contribution in each scenario.
Peers are ranked by the number of videos served by each one.
They exhibit a similar pattern and only differ in the tails, where CPPro gives higher contributios, which are not significant to the total results as shown in fig.~\ref{fig:contrib-normal} and \ref{fig:contrib-shift}.
However, in the scenario C the peer contribution is almost identical in CPPro and PROP. 

The advantage of CPPro to PROP is shown in fig.~\ref{fig:atd-normal}, \ref{fig:atd-shift}, and \ref{fig:atd-zipf}  which show the number of replicas the requested videos at each request event for all scenarios.
We see that CPPro result in fewer replicas comparing to those of PROP.
Figure~\ref{fig:atd-zipf} that for scenario C,  CPPro has much fewer replicas than those of PROP.
It shows that many videos are not cached by CPPro.
That does not affect the peers contribution comparing to PROP.


\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
\caption{Percentage of Cached events and Not-Cached events in CPPro and PROP.}
\label{tab:stacked1}
\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
\begin{tabular}{|l|l|c|c|c|c|}
\hline
Scenario & Type & Cached (times)& Not-Cached (times) & Cached (PetaByte) & Not-Cached (PetaByte)\\
\hline
A & CPPro & $33.5\%$ & $66.5\%$ & $2422$ & $4808$ \\
\hline
 & PROP & $52\%$ & $48\%$ & $2416$ & $2230$\\
\hline

B & CPPro & $34.8\%$ & $65.2\%$ & $2423$ & $4540$\\
\hline
 & PROP & $52.6\%$ & $47.4\%$  &  $2415$  &  $2176$ \\
\hline

C & CPPro & $32.4\%$ & $67.6\%$  & $2435.5$ & $5079.5$ \\
\hline
 & PROP & $67.7\%$ & $32.3\%$ &  $2435.3$ & $1161.9$ \\
\hline
\end{tabular}
\end{table}



\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
\caption{Percentage cached and not-cached events for each video popularity phase in CPPro.}
\label{tab:stacked2}
\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
\begin{tabular}{|l|l|c|c|c|}
\hline
Scenario & Type/Events & Before-Peak & At-Peak  & After-Peak \\
\hline
A & CPPro Cached & $8.2\%$ & $1.2\%$ & $24.1\%$  \\
\hline
 & CPPro Not-Cached & $11.2\%$ & $0.8\%$ & $54.5\%$ \\
 \hline

B & CPPro Cached & $6.2\%$ & $1.2\%$ & $29.8\%$ \\
\hline
 & CPPro Not-Cached & $5.2\%$ & $0.8\%$ & $56.8\%$ \\
\hline

C & CPPro Cached & $8.0\%$ & $1.8\%$ & $22.7\%$ \\
\hline
 & CPPro Not-Cached & $15.1\%$ & $0.8\%$ & $51.6\%$ \\
\hline
\end{tabular}
\end{table}


\begin{figure}[!t]
\begin{center}
\includegraphics[scale=0.5]{../../hindawi/graphs/new/probability-intuitive.eps}
\end{center}
\caption{Process how's a video will be cached or not by a peer. Top part for PROP and bottom part for CPPro. 
$u_r$ is utility function for a requested video.  
$u_c$min is utility function for a video inside peer's storage.
}
\label{fig:cached-notcached}
\end{figure} 


When a peer requests a video from another peer, a peer has to decide whether a peer wants to cache the video or not to cache the video based on the utility function value.  
If a peer decided to cache a video, we called it cached event.
If a peer did not decide to cache a video, we called it not-cached event.
We breakdown how many cache events occur in our simulation as shown in table.\ref{tab:stacked1}.
Furthermore, we breakdown again by video phase popularity for CPROP's cached and not-cached events as shown in table.~\ref{tab:stacked2}.

From table.\ref{tab:stacked1}, we can see that CPPro cached less videos compared to PROP for all scenarios.
In scenario A, CPPro are cached $33\%$ of requested video compared to $52\%$ in PROP.  
In scenario B, we also have similar number where CPPro are cached $34.8\%$ of requested video compared to $52.6\%$. 
In scenario C, CPPro are cached $32.4\%$ of requested video compared to $67.7\%$ in PROP.
However, by summing data volume for cached events and no-cached events, we see that CPPro deliver or contribute of videos delivery more than PROP. 
These number quantifies our previous analysis. 

In table~\ref{tab:stacked2}, we can see that most of cached events and not-cached events for CPPro occured when a requested video was estimated as after-peak phase.
In scenario A, cached events occured in after-peak phase around $24.1\%$ from total events (cached events and not-cached events). 
Similarly in not-cached events, events of a peer was not cache a requested video occured in after-peak phase around $54.5\%$ from total events.
Scenario B also shows similar result where percentage of cached events occured in after-peak phase is $29.8\%$ from total events and percentage of not-cached events in after-peak phase is $56\%$ from total events.
Scenario C shows similar result where percentage of cached events occured in after-peak phase is $22.7\%$ from total events and percentage of not-cached events in after-peak phase is $51.6\%$ from total events.
Intuitively , We learn from these numbers that in at-peak phase, many replicas available thus a peer in CPPro system is decided to cache less video.

As we mentioned before that a peer decision to cache to not-cached a video is based on utility function value.
We want to know what makes replica in CPPro is lower than PROP.
Assume a peer requests a video with utility function $u_r$ and the minimum utility function inside peer's cache is $u_c$-min as shown in fig.~\ref{fig:cached-notcached} where we have five videos inside peer's cache.
Intuitively, When a requested video in after-peak phase, while videos inside peer's storage are in at-peak phase then in CPPro case high probability that a requested video will not be cached.  
In PROP case, since PROP does not has video popularity phase the probability of a requested video will not be cached is lower than CPPro.
We also calculate the Kolmogorov-Smirnov statistic on two samples and we find that for all scenarios the $p$-values are less than $0.1$ thus we consider the result are significant. 



Figure \ref{fig:freq-normal}, \ref{fig:freq-shift}, and \ref{fig:freq-zipf} show the frequency of a video stay in peers compared between CPPro and PROP.
As all figure show CPPro has higher frequency than PROP to stay in peers except for the beginning rank of data where CPPro has same frequency with PROP in first and second scenario. 
In the third scenario, in the beginning rank of data CPPro has lower frequency than PROP, then around rank 1000 CPPro has higher frequency than PROP until the end of data. 
The frequency a video stay in a video can also be viewed in fig \ref{fig:duration-normal},  \ref{fig:duration-shift}, and \ref{fig:duration-zipf}, where in CPPro some videos have longer cache duration than PROP, while others have shorter cache duration than PROP.  
Thus, we can see the relationship between cache duration and frequency a video stays in peers. 


\section{Summary}
This chapter presents a scheme for peer-to-peer network can help CDN to deliver the content over the Internet. 
We show that by introducing $z$ factor to utility function CPPro can maintain same peer contribution while reducing number of replicas.
We found that there are no much different all scenario in term of peer contribution to deliver a video. 
However, we found that in the all scenarios, CPPro gives lower replicas than PROP. 
This is because in CPPro, we found intuitively that probability not-cached events occur are higher than cached events, futhermore compared to PROP, probability a peer is not cache a requested video is higher in CPPro compared to PROP.
Therefore, in CPPro the numbers of available replicas are lower than PROP. 
We also did the significance test to the number of replicas using the Kolmogorov-Smirnov statistic on two samples and we find that for all scenarios the $p$-values are less than $1$\% thus the results are significant. 

Some areas of improvement that we have identified for future are: (1) since we know the CPPro offer a little bit peer contribution with less replica, we are interested to know the energy trade-off of this peer-assisted CDN architecture in order to know how much energy saving by ISP and how much increase of energy at users home gateway side in this architecture since we have higher peer contribution.   
(2) Involving the different popularity model from different geographically VoD service.
This is very important to see the system behavior when receiving request from different location with different popularity while still in the same global CDN service. 
Futhermore, we can exploit this behavior for commercial ads in VoD service.